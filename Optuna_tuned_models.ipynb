{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffbaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose, pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import compose, pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import Optional\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, r2_score\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna import create_study\n",
    "from sklearn import compose\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor\n",
    "import plotly.express as px\n",
    "#website help from \n",
    "#https://medium.com/@walter_sperat/using-optuna-with-sklearn-the-right-way-part-1-6b4ad0ab2451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframes/df_normal_quality.csv', index_col=0)\n",
    "y = df.SalePrice\n",
    "X = df.drop(['PID', 'SalePrice'], axis =1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b841c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "#from category_encoders import WOEEncoder\n",
    "\n",
    "def instantiate_ordinal_encoder(trial: Trial)-> OrdinalEncoder:\n",
    "    params = {\n",
    "        'handle_unknown': \"use_encoded_value\", \n",
    "        'unknown_value': -1\n",
    "    }\n",
    "    \n",
    "    return OrdinalEncoder(**params)\n",
    "\n",
    "# def instantiate_onehot_encoder(trial: Trial)-> OneHotEncoder:\n",
    "#     params = {\n",
    "#         'handle_unknown': 'ignore',\n",
    "#         'drop': trial.suggest_categorical('drop', [None, 'first'])\n",
    "#     }\n",
    "    \n",
    "#     return OneHotEncoder(**params)\n",
    "\n",
    "def instantiate_onehot_encoder(trial: Trial)-> OneHotEncoder:\n",
    "    params = {\n",
    "        'handle_unknown': 'ignore',\n",
    "        'drop': None\n",
    "    }\n",
    "    \n",
    "    return OneHotEncoder(**params)\n",
    "    \n",
    "Encoder = (\n",
    "    OrdinalEncoder |\n",
    "    OneHotEncoder \n",
    "    )\n",
    "\n",
    "def instantiate_encoder (trial : Trial) -> Encoder:\n",
    "    encoding_method = trial.suggest_categorical(\n",
    "        'encoding_method', ['ordinal', 'onehot'])\n",
    "    if encoding_method =='ordinal':\n",
    "        encoder = instantiate_ordinal_encoder(trial)\n",
    "    elif encoding_method =='onehot':\n",
    "        encoder = instantiate_onehot_encoder(trial)\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "\n",
    "Scaler = (\n",
    "  StandardScaler |\n",
    "  MinMaxScaler |\n",
    "  MaxAbsScaler |\n",
    "  RobustScaler\n",
    ")\n",
    "\n",
    "def instantiate_scaler(trial : Trial) -> Scaler:\n",
    "    method = trial.suggest_categorical(\n",
    "    'scaling_method', ['standard', 'minmax', 'maxabs', 'robust']\n",
    "    )\n",
    "    if method=='standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif method=='minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif method=='maxabs':\n",
    "        scaler = MaxAbsScaler()\n",
    "    elif method=='robust':\n",
    "        scaler = RobustScaler()\n",
    "        \n",
    "    return scaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def instantiate_processor(trial : Trial, \n",
    "                          numerical_columns : list[str], \n",
    "                          categorical_columns : list[str]) -> ColumnTransformer:\n",
    "    \n",
    "    numerical_pipeline = instantiate_scaler(trial)\n",
    "    categorical_pipeline = instantiate_encoder(trial)\n",
    "   # numerical_pipeline = StandardScaler()\n",
    "    #categorical_pipeline = OneHotEncoder(handle_unknown=\"ignore\", drop='first')\n",
    "    \n",
    "#     numerical_pipeline = instantiate_numerical_pipeline(trial)\n",
    "#     categorical_pipeline = instantiate_categorical_pipeline(trial)\n",
    "    \n",
    "    processor = ColumnTransformer([\n",
    "        ('numerical_pipeline', numerical_pipeline, numerical_columns),\n",
    "        ('categorical_pipeline', categorical_pipeline, categorical_columns)\n",
    "    ])\n",
    "    return processor\n",
    "\n",
    "def instantiate_processor_ordinal(trial : Trial, \n",
    "                          numerical_columns : list[str], \n",
    "                          categorical_columns : list[str]) -> ColumnTransformer:\n",
    "    \n",
    "    numerical_pipeline = instantiate_scaler(trial)\n",
    "    categorical_pipeline = instantiate_ordinal_encoder(trial)\n",
    "\n",
    "    processor = ColumnTransformer([\n",
    "        ('numerical_pipeline', numerical_pipeline, numerical_columns),\n",
    "        ('categorical_pipeline', categorical_pipeline, categorical_columns)\n",
    "    ])\n",
    "    return processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7540b",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_lasso(trial : Trial) -> Lasso:\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", .00001, .001, log=True)\n",
    "    }\n",
    "\n",
    "    return Lasso(**params)\n",
    "\n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], \n",
    "                      categorical_columns : list[str]) -> Pipeline:\n",
    "    \n",
    "    processor = instantiate_processor(\n",
    "        trial, numerical_columns, categorical_columns\n",
    "    )\n",
    "    \n",
    "    learner = instantiate_lasso(trial)\n",
    "    \n",
    "    model_pipe = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "    ])\n",
    "    \n",
    "    model = compose.TransformedTargetRegressor(regressor= model_pipe,\n",
    "                                                func=np.log, inverse_func=np.exp)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective_lasso(trial : Trial, X : DataFrame,\n",
    "              y : np.ndarray | Series, \n",
    "              numerical_columns : Optional[list[str]]=None, \n",
    "              categorical_columns : Optional[list[str]]=None, \n",
    "              random_state : int=42) -> float:\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = [\n",
    "            *X.select_dtypes(exclude=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = [\n",
    "            *X.select_dtypes(include=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    model = instantiate_model(trial, numerical_columns, categorical_columns)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X, y, scoring= r2, cv=kf)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbca889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "study_lasso = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "study_lasso.optimize(lambda trial: objective_lasso(trial, X, y), n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_lasso.best_value)\n",
    "print(study_lasso.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = []\n",
    "score = []\n",
    "parameters = []\n",
    "optuna_dict = {}\n",
    "trials = range(200)\n",
    "\n",
    "for trial in trials:\n",
    "    trial_number.append(study_lasso.get_trials()[trial].number)\n",
    "    score.append(study_lasso.get_trials()[trial].value)\n",
    "    parameters.append(list(study_lasso.get_trials()[trial].params.items()))\n",
    "\n",
    "optuna_dict['Trial'] = trial_number\n",
    "optuna_dict['Score'] = score\n",
    "optuna_dict['Parameters'] = parameters\n",
    "\n",
    "optuna_lasso = pd.DataFrame.from_dict(optuna_dict)\n",
    "optuna_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604eb947",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "optuna_lasso.Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    " optuna_lasso['alpha'] = optuna_lasso.Parameters.apply(lambda x: x[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    " optuna_lasso['encoding'] = optuna_lasso.Parameters.apply(lambda x: x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a05f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_lasso['scaling'] = optuna_lasso.Parameters.apply(lambda x: x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_lasso.to_csv('dataframes/optuna/optuna_lasso.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bffdb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(optuna_lasso,\n",
    "                 x=\"Trial\", \n",
    "                 y=\"Score\", \n",
    "                 hover_data=['Parameters'],\n",
    "                labels = {'Trial': 'Optuna Trial', 'Score': 'Score (R-Squared)'},\n",
    "                title = 'Lasso tuned with Optuna after 200 trials  <br><sup> Best Score: 0.9508126</sup>')\n",
    "\n",
    "fig.update_layout(\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=8,\n",
    "        font_family=\"Rockwell\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"images/lasso_optuna.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ea4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(optuna_lasso,\n",
    "                 x=\"Trial\", \n",
    "                 y=\"Score\", \n",
    "                 hover_data=['Parameters'],\n",
    "                 color = 'scaling',\n",
    "                labels = {'Trial': 'Optuna Trial', 'Score': 'Score (R-Squared)'},\n",
    "                title = 'Lasso tuned with Optuna after 200 trials  <br><sup> Best Score: 0.9508126</sup>')\n",
    "\n",
    "fig.update_layout(\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=8,\n",
    "        font_family=\"Rockwell\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"images/lasso_optuna_scaling.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(optuna_lasso,\n",
    "                 x=\"Trial\", \n",
    "                 y=\"Score\", \n",
    "                 hover_data=['Parameters'],\n",
    "                 color = 'alpha',\n",
    "                labels = {'Trial': 'Optuna Trial', 'Score': 'Score (R-Squared)'},\n",
    "                title = 'Lasso tuned with Optuna after 200 trials  <br><sup> Best Score: 0.9508126</sup>')\n",
    "\n",
    "fig.update_layout(\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=8,\n",
    "        font_family=\"Rockwell\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"images/lasso_optuna_alpha.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cf6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(optuna_lasso,\n",
    "                 x=\"Trial\", \n",
    "                 y=\"Score\", \n",
    "                 hover_data=['Parameters'],\n",
    "                 color = 'encoding',\n",
    "                labels = {'Trial': 'Optuna Trial', 'Score': 'Score (R-Squared)'},\n",
    "                title = 'Lasso tuned with Optuna after 200 trials  <br><sup> Best Score: 0.9508126</sup>')\n",
    "\n",
    "fig.update_layout(\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=8,\n",
    "        font_family=\"Rockwell\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"images/lasso_optuna_encoding.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4a63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf3ba406",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eceabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_ridge(trial : Trial) -> Ridge:\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1, 100, log=True)\n",
    "    }\n",
    "\n",
    "    return Ridge(**params)\n",
    "\n",
    "\n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], \n",
    "                      categorical_columns : list[str]) -> Pipeline:\n",
    "    \n",
    "    processor = instantiate_processor(\n",
    "        trial, numerical_columns, categorical_columns\n",
    "    )\n",
    "    \n",
    "    learner = instantiate_ridge(trial)\n",
    "    \n",
    "    model_pipe = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "    ])\n",
    "    \n",
    "    model = compose.TransformedTargetRegressor(regressor= model_pipe,\n",
    "                                                func=np.log, inverse_func=np.exp)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective_ridge(trial : Trial, X : DataFrame,\n",
    "              y : np.ndarray | Series, \n",
    "              numerical_columns : Optional[list[str]]=None, \n",
    "              categorical_columns : Optional[list[str]]=None, \n",
    "              random_state : int=42) -> float:\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = [\n",
    "            *X.select_dtypes(exclude=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = [\n",
    "            *X.select_dtypes(include=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    model = instantiate_model(trial, numerical_columns, categorical_columns)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X, y, scoring= r2, cv=kf)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "study_ridge = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "#study_ridge.optimize(lambda trial: objective_ridge(trial, X, y), n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_ridge.best_value)\n",
    "print(study_ridge.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3792b",
   "metadata": {},
   "source": [
    "# EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_en(trial : Trial) -> ElasticNet:\n",
    "    params = {\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", .00001, .001, log=True),\n",
    "        'l1_ratio': trial.suggest_float('l1_ratio', .1, .7, log = True)\n",
    "    }\n",
    "\n",
    "    return ElasticNet(**params)\n",
    "\n",
    "\n",
    "\n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], \n",
    "                      categorical_columns : list[str]) -> Pipeline:\n",
    "    \n",
    "    processor = instantiate_processor(\n",
    "        trial, numerical_columns, categorical_columns\n",
    "    )\n",
    "    \n",
    "    learner = instantiate_en(trial)\n",
    "    \n",
    "    model_pipe = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "    ])\n",
    "    \n",
    "    model = compose.TransformedTargetRegressor(regressor= model_pipe,\n",
    "                                                func=np.log, inverse_func=np.exp)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective_en(trial : Trial, X : DataFrame,\n",
    "              y : np.ndarray | Series, \n",
    "              numerical_columns : Optional[list[str]]=None, \n",
    "              categorical_columns : Optional[list[str]]=None, \n",
    "              random_state : int=42) -> float:\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = [\n",
    "            *X.select_dtypes(exclude=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = [\n",
    "            *X.select_dtypes(include=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    model = instantiate_model(trial, numerical_columns, categorical_columns)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X, y, scoring= r2, cv=kf)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd4f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "study_en = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "#study_en.optimize(lambda trial: objective_en(trial, X, y), n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95714ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after adding in the L1 value\n",
    "print(study_en.best_value)\n",
    "print(study_en.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10243543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_en.best_value)\n",
    "print(study_en.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f92177",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe05544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_xgb(trial : Trial) -> XGBRegressor:\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", .001, .1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 4),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5)\n",
    "    }\n",
    "\n",
    "    return XGBRegressor(**params)\n",
    "\n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], \n",
    "                      categorical_columns : list[str]) -> Pipeline:\n",
    "    \n",
    "    processor = instantiate_processor(\n",
    "        trial, numerical_columns, categorical_columns\n",
    "    )\n",
    "    \n",
    "    learner = instantiate_xgb(trial)\n",
    "    \n",
    "    model_pipe = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "    ])\n",
    "    \n",
    "    model = compose.TransformedTargetRegressor(regressor= model_pipe,\n",
    "                                                func=np.log, inverse_func=np.exp)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective_xgb(trial : Trial, X : DataFrame,\n",
    "              y : np.ndarray | Series, \n",
    "              numerical_columns : Optional[list[str]]=None, \n",
    "              categorical_columns : Optional[list[str]]=None, \n",
    "              random_state : int=42) -> float:\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = [\n",
    "            *X.select_dtypes(exclude=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = [\n",
    "            *X.select_dtypes(include=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    model = instantiate_model(trial, numerical_columns, categorical_columns)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X, y, scoring= r2, cv=kf)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeee34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "study_xgb = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "study_xgb.optimize(lambda trial: objective_xgb(trial, X, y), n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_xgb.best_value)\n",
    "print(study_xgb.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = []\n",
    "score = []\n",
    "parameters = []\n",
    "optuna_dict = {}\n",
    "trials = range(200)\n",
    "\n",
    "for trial in trials:\n",
    "    trial_number.append(study_xgb.get_trials()[trial].number)\n",
    "    score.append(study_xgb.get_trials()[trial].value)\n",
    "    parameters.append(list(study_xgb.get_trials()[trial].params.items()))\n",
    "\n",
    "optuna_dict['Trial'] = trial_number\n",
    "optuna_dict['Score'] = score\n",
    "optuna_dict['Parameters'] = parameters\n",
    "\n",
    "optuna_xgb = pd.DataFrame.from_dict(optuna_dict)\n",
    "optuna_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbf43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_xgb.to_csv('dataframes/optuna/optuna_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'scaling_method': 'standard', \n",
    " 'encoding_method': 'onehot', 'drop': 'first', \n",
    " 'n_estimators': 987, \n",
    " 'learning_rate': 0.04571203871971512, \n",
    " 'max_depth': 3, \n",
    " 'subsample': 0.5029585844426339, \n",
    " 'colsample_bytree': 0.8889268050013618, \n",
    " 'min_child_weight': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787f3f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "pd.set_option('display.max_rows', None)\n",
    "#optuna_xgb.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_xgb['scaling'] =optuna_xgb.Parameters.apply(lambda x: x[0][1])\n",
    "optuna_xgb['encoding'] = optuna_xgb.Parameters.apply(lambda x: x[1][1])\n",
    "optuna_xgb['n_estimators'] = optuna_xgb.Parameters.apply(lambda x: x[-6][1])\n",
    "optuna_xgb['learning_rate'] = optuna_xgb.Parameters.apply(lambda x: x[-5][1])\n",
    "optuna_xgb['max_depth'] = optuna_xgb.Parameters.apply(lambda x: x[-4][1])\n",
    "optuna_xgb['subsample'] = optuna_xgb.Parameters.apply(lambda x: x[-3][1])\n",
    "optuna_xgb['colsample'] = optuna_xgb.Parameters.apply(lambda x: x[-2][1])\n",
    "optuna_xgb['min_child'] = optuna_xgb.Parameters.apply(lambda x: x[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(optuna_xgb.loc[optuna_xgb.Score > .93],\n",
    "                 x=\"Trial\", \n",
    "                 y=\"Score\", \n",
    "                 color = 'learning_rate',\n",
    "                 hover_data=['Parameters'],\n",
    "                labels = {'Trial': 'Optuna Trial', 'Score': 'Score (R-Squared)'},\n",
    "                title = 'XGB tuned with Optuna after 200 trials  <br><sup> Best Score: 0.9539</sup>')\n",
    "\n",
    "fig.update_layout(\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=8,\n",
    "        font_family=\"Rockwell\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9821b",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47153b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_rf(trial : Trial) -> RandomForestRegressor:\n",
    "    params = {\n",
    "    'bootstrap':trial.suggest_categorical('bootstrap', [True]),\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 250, 500),\n",
    "    'max_depth': trial.suggest_int('max_depth', 50, 75),\n",
    "    'min_samples_split': trial.suggest_int('min_samples_split', 4, 6),\n",
    "    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    }\n",
    "    \n",
    "    return RandomForestRegressor(**params)\n",
    "  \n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], \n",
    "                      categorical_columns : list[str]) -> Pipeline:\n",
    "    \n",
    "    processor = instantiate_processor_ordinal(\n",
    "        trial, numerical_columns, categorical_columns\n",
    "    )\n",
    "    \n",
    "    learner = instantiate_rf(trial)\n",
    "    \n",
    "    model_pipe = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "    ])\n",
    "    \n",
    "    model = compose.TransformedTargetRegressor(regressor= model_pipe,\n",
    "                                                func=np.log, inverse_func=np.exp)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective_rf(trial : Trial, X : DataFrame,\n",
    "              y : np.ndarray | Series, \n",
    "              numerical_columns : Optional[list[str]]=None, \n",
    "              categorical_columns : Optional[list[str]]=None, \n",
    "              random_state : int=42) -> float:\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = [\n",
    "            *X.select_dtypes(exclude=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = [\n",
    "            *X.select_dtypes(include=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    model = instantiate_model(trial, numerical_columns, categorical_columns)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X, y, scoring= r2, cv=kf)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "study_rf = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "study_rf.optimize(lambda trial: objective_rf(trial, X, y), n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cd543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_rf.best_value)\n",
    "print(study_rf.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda6146",
   "metadata": {},
   "source": [
    "# gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d09f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_gbr(trial : Trial) -> GradientBoostingRegressor:\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 500, 1000),\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1, log=True),\n",
    "    'max_depth': trial.suggest_int ('max_depth', 2, 6),\n",
    "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "    'min_samples_split': trial.suggest_int ('min_sample_split', 6, 10),\n",
    "    'min_samples_leaf': trial.suggest_int ('min_sample_leaf', 1, 10)\n",
    "    }\n",
    "    \n",
    "    return GradientBoostingRegressor(**params)\n",
    "\n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], \n",
    "                      categorical_columns : list[str]) -> Pipeline:\n",
    "    \n",
    "    processor = instantiate_processor_ordinal(\n",
    "        trial, numerical_columns, categorical_columns\n",
    "    )\n",
    "    \n",
    "    learner = instantiate_gbr(trial)\n",
    "    \n",
    "    model_pipe = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "    ])\n",
    "    \n",
    "    model = compose.TransformedTargetRegressor(regressor= model_pipe,\n",
    "                                                func=np.log, inverse_func=np.exp)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective_gbr(trial : Trial, X : DataFrame,\n",
    "              y : np.ndarray | Series, \n",
    "              numerical_columns : Optional[list[str]]=None, \n",
    "              categorical_columns : Optional[list[str]]=None, \n",
    "              random_state : int=42) -> float:\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = [\n",
    "            *X.select_dtypes(exclude=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = [\n",
    "            *X.select_dtypes(include=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    model = instantiate_model(trial, numerical_columns, categorical_columns)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X, y, scoring= r2, cv=kf)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "study_gbr = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "study_gbr.optimize(lambda trial: objective_gbr(trial, X, y), n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_gbr.best_value)\n",
    "print(study_gbr.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66d6f0",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da656a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_ada(trial : Trial) -> AdaBoostRegressor:\n",
    "    params = {\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1, log=True),\n",
    "    'loss': trial.suggest_categorical('loss',['linear', 'square', 'exponential']),\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 1, 1000)\n",
    "    }\n",
    "    \n",
    "    return AdaBoostRegressor(**params)\n",
    "\n",
    "def instantiate_model(trial : Trial, numerical_columns : list[str], \n",
    "                      categorical_columns : list[str]) -> Pipeline:\n",
    "    \n",
    "    processor = instantiate_processor_ordinal(\n",
    "        trial, numerical_columns, categorical_columns\n",
    "    )\n",
    "    \n",
    "    learner = instantiate_ada(trial)\n",
    "    \n",
    "    model_pipe = Pipeline([\n",
    "    ('processor', processor),\n",
    "    ('model', learner)\n",
    "    ])\n",
    "    \n",
    "    model = compose.TransformedTargetRegressor(regressor= model_pipe,\n",
    "                                                func=np.log, inverse_func=np.exp)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def objective_ada(trial : Trial, X : DataFrame,\n",
    "              y : np.ndarray | Series, \n",
    "              numerical_columns : Optional[list[str]]=None, \n",
    "              categorical_columns : Optional[list[str]]=None, \n",
    "              random_state : int=42) -> float:\n",
    "    \n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = [\n",
    "            *X.select_dtypes(exclude=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = [\n",
    "            *X.select_dtypes(include=['object', 'category']).columns\n",
    "        ]\n",
    "    \n",
    "    model = instantiate_model(trial, numerical_columns, categorical_columns)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    scores = cross_val_score(model, X, y, scoring= r2, cv=kf)\n",
    "    \n",
    "    return np.min([np.mean(scores), np.median([scores])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b30841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "\n",
    "study_ada = create_study(study_name='optimization', direction='maximize')\n",
    "\n",
    "study_ada.optimize(lambda trial: objective_ada(trial, X, y), n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed226d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4faa7a11",
   "metadata": {},
   "source": [
    "# Loop through?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041506c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [study_lasso, study_ridge, study_en, study_xgb, study_rf, study_gbr, study_ada]\n",
    "objectives = [objective_lasso, \n",
    "              objective_ridge, \n",
    "              objective_en,\n",
    "              objective_xgb,\n",
    "              objective_rf,\n",
    "              objective_gbr,\n",
    "              objective_ada]\n",
    "\n",
    "# for study, objective in zip(studies, objectives):\n",
    "#     study.optimize(lambda trial: objective(trial, X, y), n_trials=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e1831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in studies:\n",
    "    print (study.best_value)\n",
    "    print (study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
